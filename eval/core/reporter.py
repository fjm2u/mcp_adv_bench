"""ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»ä¿å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
from models.scenario import Result


class Reporter:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_name: str):
        self.dataset_name = dataset_name
        self.output_dir = Path(f"results/{dataset_name}")
    
    def generate_report(self, results: List[Result], scenario_stats: Dict[str, Any] = None, 
                       execution_llm_info: Dict[str, str] = None, evaluation_llm_info: Dict[str, str] = None) -> Dict[str, Any]:
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            results: å®Ÿè¡Œçµæœã®ãƒªã‚¹ãƒˆ
            scenario_stats: å„ã‚·ãƒŠãƒªã‚ªã®çµ±è¨ˆæƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            execution_llm_info: å®Ÿè¡ŒLLMã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            evaluation_llm_info: è©•ä¾¡LLMã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
        """
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸçµæœã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        error_results = [r for r in results if hasattr(r, 'error') and r.error]
        
        # åŸºæœ¬ãƒ¬ãƒãƒ¼ãƒˆæ§‹é€ 
        report = {
            'dataset': self.dataset_name,
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_scenarios': len(results),
                'errors': len(error_results)
            }
        }
        
        # LLMãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if execution_llm_info or evaluation_llm_info:
            report['metadata'] = {}
            if execution_llm_info:
                report['metadata']['execution_llm'] = execution_llm_info
            if evaluation_llm_info:
                report['metadata']['evaluation_llm'] = evaluation_llm_info
        
        # çµ±è¨ˆæƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if scenario_stats:
            # statisticsã‚’ã‚³ãƒ”ãƒ¼ã—ã¦resultsã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
            serializable_stats = {}
            attack_scenarios = []
            control_scenarios = []
            
            for scenario_name, stats in scenario_stats.items():
                stat_copy = stats.copy()
                # resultsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯Resultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’dictã«å¤‰æ›ã—ã€åå‰ã‚’å¤‰æ›´
                if 'results' in stat_copy:
                    stat_copy['iterations_detail'] = [r.to_dict() for r in stat_copy['results']]
                    
                    # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã‚’é™¤å¤–ã—ã¦çµ±è¨ˆã‚’è¨ˆç®—
                    valid_results = [r for r in stat_copy['results'] if not r.error]
                    error_results = [r for r in stat_copy['results'] if r.error]
                    
                    # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
                    stat_copy['error_count'] = len(error_results)
                    stat_copy['valid_iterations'] = len(valid_results)
                    
                    # ã‚·ãƒŠãƒªã‚ªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šï¼ˆã‚¨ãƒ©ãƒ¼ä»¥å¤–ã§åˆ¤å®šï¼‰
                    is_attack = any(r.attack_case for r in valid_results) if valid_results else any(r['attack_case'] for r in stat_copy['iterations_detail'])
                    
                    # æˆåŠŸç‡ã‚’è¨ˆç®—ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é™¤å¤–ï¼‰
                    if len(valid_results) > 0:
                        success_count = sum(1 for r in valid_results if r.meets_expected_behavior)
                        success_rate = success_count / len(valid_results)
                        stat_copy['success_rate'] = f"{success_rate:.1%}"
                        stat_copy['success_count'] = success_count
                        
                        # confidenceã®å¹³å‡ã‚’è¨ˆç®—
                        confidences = []
                        for r in valid_results:
                            if hasattr(r, 'evaluation_details') and r.evaluation_details:
                                if 'confidence' in r.evaluation_details:
                                    confidences.append(r.evaluation_details['confidence'])
                        if confidences:
                            stat_copy['avg_confidence'] = sum(confidences) / len(confidences)
                    else:
                        stat_copy['success_rate'] = "N/A (all errors)"
                        stat_copy['success_count'] = 0
                        success_rate = 0
                    
                    # ã‚·ãƒŠãƒªã‚ªæ¯ã®çµ±è¨ˆã‚’åˆ†é¡
                    if is_attack:
                        attack_scenarios.append({
                            'name': scenario_name,
                            'success_count': stat_copy['success_count'],
                            'iterations': stat_copy['iterations'],
                            'valid_iterations': stat_copy['valid_iterations'],
                            'error_count': stat_copy['error_count'],
                            'success_rate': success_rate,
                            'avg_confidence': stat_copy.get('avg_confidence')
                        })
                    else:
                        control_scenarios.append({
                            'name': scenario_name,
                            'success_count': stat_copy['success_count'],
                            'iterations': stat_copy['iterations'],
                            'valid_iterations': stat_copy['valid_iterations'],
                            'error_count': stat_copy['error_count'],
                            'success_rate': success_rate,
                            'avg_confidence': stat_copy.get('avg_confidence')
                        })
                    
                    del stat_copy['results']  # å…ƒã®resultsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‰Šé™¤
                serializable_stats[scenario_name] = stat_copy
            
            report['results'] = serializable_stats
            
            # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’æ›´æ–°
            report['summary']['iterations_per_scenario'] = next(iter(scenario_stats.values()))['iterations']
            
            # æ”»æ’ƒã‚·ãƒŠãƒªã‚ªã®çµ±è¨ˆ
            if attack_scenarios:
                total_attack_iterations = sum(s['iterations'] for s in attack_scenarios)
                total_valid_attack_iterations = sum(s['valid_iterations'] for s in attack_scenarios)
                total_attack_successes = sum(s['success_count'] for s in attack_scenarios)
                total_attack_errors = sum(s.get('error_count', 0) for s in attack_scenarios)
                
                if total_valid_attack_iterations > 0:
                    attack_block_rate = total_attack_successes / total_valid_attack_iterations
                    # å…¨ä½“ã®å¹³å‡confidenceã‚’è¨ˆç®—
                    avg_confidences = [s['avg_confidence'] for s in attack_scenarios if s.get('avg_confidence') is not None]
                    overall_avg_confidence = sum(avg_confidences) / len(avg_confidences) if avg_confidences else None
                else:
                    attack_block_rate = 0
                    overall_avg_confidence = None
                
                report['summary']['attack_scenarios'] = {
                    'count': len(attack_scenarios),
                    'total_iterations': total_attack_iterations,
                    'valid_iterations': total_valid_attack_iterations,
                    'error_count': total_attack_errors,
                    'overall_block_rate': f"{attack_block_rate:.1%}",
                    'avg_confidence': overall_avg_confidence,
                    'details': [
                        {
                            'name': s['name'],
                            'block_rate': f"{s['success_rate']:.1%}",
                            'blocked': f"{s['success_count']}/{s['valid_iterations']}",
                            'errors': s.get('error_count', 0),
                            'total': s['iterations'],
                            'avg_confidence': s.get('avg_confidence')
                        }
                        for s in attack_scenarios
                    ]
                }
            
            # åˆ¶å¾¡ã‚·ãƒŠãƒªã‚ªã®çµ±è¨ˆ
            if control_scenarios:
                total_control_iterations = sum(s['iterations'] for s in control_scenarios)
                total_valid_control_iterations = sum(s['valid_iterations'] for s in control_scenarios)
                total_control_successes = sum(s['success_count'] for s in control_scenarios)
                total_control_errors = sum(s.get('error_count', 0) for s in control_scenarios)
                
                if total_valid_control_iterations > 0:
                    control_pass_rate = total_control_successes / total_valid_control_iterations
                    # å…¨ä½“ã®å¹³å‡confidenceã‚’è¨ˆç®—
                    avg_confidences = [s['avg_confidence'] for s in control_scenarios if s.get('avg_confidence') is not None]
                    overall_avg_confidence = sum(avg_confidences) / len(avg_confidences) if avg_confidences else None
                else:
                    control_pass_rate = 0
                    overall_avg_confidence = None
                
                report['summary']['control_scenarios'] = {
                    'count': len(control_scenarios),
                    'total_iterations': total_control_iterations,
                    'valid_iterations': total_valid_control_iterations,
                    'error_count': total_control_errors,
                    'overall_pass_rate': f"{control_pass_rate:.1%}",
                    'avg_confidence': overall_avg_confidence,
                    'details': [
                        {
                            'name': s['name'],
                            'pass_rate': f"{s['success_rate']:.1%}",
                            'passed': f"{s['success_count']}/{s['valid_iterations']}",
                            'errors': s.get('error_count', 0),
                            'total': s['iterations'],
                            'avg_confidence': s.get('avg_confidence')
                        }
                        for s in control_scenarios
                    ]
                }
            
            # å…¨ä½“ã®æˆåŠŸç‡ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é™¤å¤–ï¼‰
            total_iterations = sum(stats['iterations'] for stats in scenario_stats.values())
            total_valid_iterations = sum(s['valid_iterations'] for s in list(attack_scenarios) + list(control_scenarios))
            total_successes = sum(s['success_count'] for s in list(attack_scenarios) + list(control_scenarios))
            total_errors = sum(s.get('error_count', 0) for s in list(attack_scenarios) + list(control_scenarios))
            
            if total_valid_iterations > 0:
                overall_success_rate = total_successes / total_valid_iterations
            else:
                overall_success_rate = 0
            
            report['summary']['overall_success_rate'] = f"{overall_success_rate:.1%}"
            report['summary']['total_valid_iterations'] = total_valid_iterations
            report['summary']['total_errors'] = total_errors
            
        else:
            # çµ±è¨ˆæƒ…å ±ãŒãªã„å ´åˆã¯ã€å˜ä¸€å®Ÿè¡Œã®çµæœã‚’å‡¦ç†
            # ã‚¨ãƒ©ãƒ¼ã‚’é™¤å¤–ã—ãŸçµæœã‚’åˆ†é¡
            valid_results = [r for r in results if not r.error]
            attack_results = [r for r in valid_results if r.attack_case]
            control_results = [r for r in valid_results if not r.attack_case]
            total_errors = len([r for r in results if r.error])
            
            report['summary']['total_errors'] = total_errors
            report['summary']['total_valid_results'] = len(valid_results)
            
            if attack_results:
                attack_blocked = sum(1 for r in attack_results if r.meets_expected_behavior)
                attack_block_rate = attack_blocked / len(attack_results) if attack_results else 0
                report['summary']['attack_scenarios'] = {
                    'count': len(attack_results),
                    'overall_block_rate': f"{attack_block_rate:.1%}",
                    'blocked_count': attack_blocked
                }
            
            if control_results:
                control_passed = sum(1 for r in control_results if r.meets_expected_behavior)
                control_pass_rate = control_passed / len(control_results) if control_results else 0
                report['summary']['control_scenarios'] = {
                    'count': len(control_results),
                    'overall_pass_rate': f"{control_pass_rate:.1%}",
                    'passed_count': control_passed
                }
            
            report['results'] = [r.to_dict() for r in results]
        
        return report
    
    def save_report(self, report: Dict[str, Any]) -> Path:
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        
        Args:
            report: ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
        
        Returns:
            ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"report_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return output_file
    
    def print_summary(self, report: Dict[str, Any]):
        """
        ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        
        Args:
            report: ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
        """
        print("\n" + "="*60)
        print(f"Dataset: {report['dataset']}")
        print(f"Time: {report['timestamp']}")
        print("-"*60)
        print(f"Total scenarios: {report['summary']['total_scenarios']}")
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
        if 'errors' in report['summary'] and report['summary']['errors'] > 0:
            print(f"âš ï¸  Evaluation errors: {report['summary']['errors']}")
        
        # æ–°ã—ã„ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆçµ±è¨ˆæƒ…å ±ãŒã‚ã‚‹å ´åˆï¼‰
        if 'total_errors' in report['summary'] and report['summary']['total_errors'] > 0:
            total_scenarios = report['summary']['total_scenarios']
            iterations_per = report['summary'].get('iterations_per_scenario', 1)
            total_iterations = total_scenarios * iterations_per
            error_rate = report['summary']['total_errors'] / total_iterations * 100
            print(f"âš ï¸  Errors: {report['summary']['total_errors']} ({error_rate:.1f}% of total iterations)")
            if 'total_valid_iterations' in report['summary']:
                print(f"   Valid evaluations: {report['summary']['total_valid_iterations']}")
        
        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ãŒã‚ã‚‹å ´åˆ
        if 'iterations_per_scenario' in report['summary']:
            print(f"Iterations per scenario: {report['summary']['iterations_per_scenario']}")
            print(f"Overall success rate: {report['summary']['overall_success_rate']} (excluding errors)")
        
        # æ”»æ’ƒã‚·ãƒŠãƒªã‚ªã®çµæœã‚’è¡¨ç¤º
        if 'attack_scenarios' in report['summary']:
            attack_info = report['summary']['attack_scenarios']
            print("\n" + "-"*60)
            print(f"ğŸ›¡ï¸  Attack Scenarios ({attack_info['count']} scenarios)")
            if 'error_count' in attack_info and attack_info['error_count'] > 0:
                print(f"   Overall block rate: {attack_info['overall_block_rate']} (excluding {attack_info['error_count']} errors)")
            else:
                print(f"   Overall block rate: {attack_info['overall_block_rate']}")
            if 'avg_confidence' in attack_info and attack_info['avg_confidence'] is not None:
                print(f"   Average confidence: {attack_info['avg_confidence']:.2f}")
            if 'details' in attack_info:
                print("   Per-scenario block rates:")
                for detail in attack_info['details']:
                    if detail.get('errors', 0) > 0:
                        print(f"     â€¢ {detail['name']}: {detail['block_rate']} ({detail['blocked']}, {detail['errors']} errors)")
                    else:
                        print(f"     â€¢ {detail['name']}: {detail['block_rate']} ({detail['blocked']})")
            elif 'blocked_count' in attack_info:
                print(f"   Blocked: {attack_info['blocked_count']}/{attack_info['count']}")
        
        # åˆ¶å¾¡ã‚·ãƒŠãƒªã‚ªã®çµæœã‚’è¡¨ç¤º
        if 'control_scenarios' in report['summary']:
            control_info = report['summary']['control_scenarios']
            print("\n" + "-"*60)
            print(f"âœ… Control Scenarios ({control_info['count']} scenarios)")
            if 'error_count' in control_info and control_info['error_count'] > 0:
                print(f"   Overall pass rate: {control_info['overall_pass_rate']} (excluding {control_info['error_count']} errors)")
            else:
                print(f"   Overall pass rate: {control_info['overall_pass_rate']}")
            if 'avg_confidence' in control_info and control_info['avg_confidence'] is not None:
                print(f"   Average confidence: {control_info['avg_confidence']:.2f}")
            if 'details' in control_info:
                print("   Per-scenario pass rates:")
                for detail in control_info['details']:
                    if detail.get('errors', 0) > 0:
                        print(f"     â€¢ {detail['name']}: {detail['pass_rate']} ({detail['passed']}, {detail['errors']} errors)")
                    else:
                        print(f"     â€¢ {detail['name']}: {detail['pass_rate']} ({detail['passed']})")
            elif 'passed_count' in control_info:
                print(f"   Passed: {control_info['passed_count']}/{control_info['count']}")
        
        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’è¡¨ç¤º
        display_errors = False
        if 'errors' in report['summary'] and report['summary']['errors'] > 0:
            display_errors = True
        elif 'total_errors' in report['summary'] and report['summary']['total_errors'] > 0:
            display_errors = True
        
        if display_errors:
            print("\n" + "-"*60)
            print("âš ï¸  Error details:")
            # resultsãŒè¾æ›¸ã®å ´åˆï¼ˆçµ±è¨ˆæƒ…å ±ï¼‰ã¨ãƒªã‚¹ãƒˆã®å ´åˆï¼ˆå˜ä¸€å®Ÿè¡Œï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œ
            if isinstance(report['results'], dict):
                # çµ±è¨ˆæƒ…å ±ã‹ã‚‰å„ã‚·ãƒŠãƒªã‚ªã®ã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
                for scenario_name, stats in report['results'].items():
                    if 'iterations_detail' in stats:
                        for detail in stats['iterations_detail']:
                            if 'error' in detail and detail['error']:
                                print(f"  â€¢ {detail['name']}: {detail.get('error_message', 'Unknown error')}")
                                break  # åŒã˜ã‚·ãƒŠãƒªã‚ªã®è¤‡æ•°ã‚¨ãƒ©ãƒ¼ã¯æœ€åˆã®1ã¤ã ã‘è¡¨ç¤º
            elif isinstance(report['results'], list):
                # å˜ä¸€å®Ÿè¡Œã®çµæœã‚’ç¢ºèª
                for result in report['results']:
                    if 'error' in result and result['error']:
                        print(f"  â€¢ {result['name']}: {result.get('error_message', 'Unknown error')}")
        
        print("="*60)